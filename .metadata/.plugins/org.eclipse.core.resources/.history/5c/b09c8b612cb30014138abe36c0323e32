#include "opencv2/video/tracking.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/calib3d/calib3d.hpp"
#include "opencv2/gpu/gpu.hpp"

#include <iostream>
#include <ctype.h>
#include <vector>
#include <sys/time.h>
#include <stdio.h>

using namespace cv;
using namespace cv::gpu;
using namespace std;

Mat image, frame0, frame1, gray, mask;
GpuMat gpu_image, gpu_frame0, gpu_frame1, gpu_gray, gpu_mask;
GpuMat prev_points, next_points, flow_status, prev_desc, next_desc;

const double ransac_thresh = 2.5f; // RANSAC inlier threshold
const double nn_match_ratio = 0.6f; // Nearest-neighbour matching ratio
const int bb_min_inliers = 100; // Minimal number of inliers to draw bounding box

Rect selection;
Point origin;
bool selectObject = false;
int trackObject = 0;


static void onMouse( int event, int x, int y, int, void* )
{
	if( selectObject )
	{
		selection.x = MIN(x, origin.x);
		selection.y = MIN(y, origin.y);
		selection.width = std::abs(x - origin.x);
		selection.height = std::abs(y - origin.y);

		selection &= Rect(0, 0, image.cols, image.rows);
	}

	switch( event )
	{
	case CV_EVENT_LBUTTONDOWN:
		origin = Point(x,y);
		selection = Rect(x,y,0,0);
		selectObject = true;
		break;
	case CV_EVENT_LBUTTONUP:
		selectObject = false;
		if( selection.width > 0 && selection.height > 0 )
			trackObject = -1;
		break;
	}
}
static void download(const GpuMat& d_mat, vector<Point2f>& vec)
{
	vec.resize(d_mat.cols);
	Mat mat(1, d_mat.cols, CV_32FC2, (void*)&vec[0]);
	d_mat.download(mat);
}
static void download(const GpuMat& d_mat, vector<uchar>& vec)
{
	vec.resize(d_mat.cols);
	Mat mat(1, d_mat.cols, CV_8UC1, (void*)&vec[0]);
	d_mat.download(mat);
}
static void drawArrows(Mat& frame, const vector<Point2f>& prevPts, const vector<Point2f>& nextPts, const vector<uchar>& status, Scalar line_color = Scalar(0, 0, 255))
{
    for (size_t i = 0; i < prevPts.size(); ++i)
    {
        if (status[i])
        {
            int line_thickness = 1;

            Point p = prevPts[i];
            Point q = nextPts[i];

            double angle = atan2((double) p.y - q.y, (double) p.x - q.x);

            double hypotenuse = sqrt( (double)(p.y - q.y)*(p.y - q.y) + (double)(p.x - q.x)*(p.x - q.x) );

            if (hypotenuse < 1.0)
                continue;

            // Here we lengthen the arrow by a factor of three.
            q.x = (int) (p.x - 3 * hypotenuse * cos(angle));
            q.y = (int) (p.y - 3 * hypotenuse * sin(angle));

            // Now we draw the main line of the arrow.
            line(frame, p, q, line_color, line_thickness);

            // Now draw the tips of the arrow. I do some scaling so that the
            // tips look proportional to the main line of the arrow.

            p.x = (int) (q.x + 9 * cos(angle + CV_PI / 4));
            p.y = (int) (q.y + 9 * sin(angle + CV_PI / 4));
            line(frame, p, q, line_color, line_thickness);

            p.x = (int) (q.x + 9 * cos(angle - CV_PI / 4));
            p.y = (int) (q.y + 9 * sin(angle - CV_PI / 4));
            line(frame, p, q, line_color, line_thickness);
        }
    }
}

int main( int argc, const char** argv )
{

	VideoCapture cap;
	Rect trackWindow;

	//cap.open("/home/scott/Aerial/aerial_navigation/photos/SoccerGoal.MOV");
	cap.open("/home/scott/Aerial/aerial_navigation/photos/SoccerGoal2.mp4");

	if( !cap.isOpened() )
	{
		cout << "***Could not initialize capturing...***\n";
		return -1;
	}
	//GoodFeaturesToTrackDetector_GPU(maxCorners=1000, qualityLevel=0.01, minDistance=0.0, blockSize=3, useHarrisDetector=false, harrisK=0.04)
	gpu::GoodFeaturesToTrackDetector_GPU good(1000, 0.1, 1.0, 3, true, 0.04);
	gpu::FAST_GPU fast(12, true, 0.05);
	//ORB_GPU(nFeatures=500, scaleFactor=1.2f, nLevels=8, edgeThreshold=31, firstLevel=0, WTA_K=2, scoreType=0, patchSize=31)
	gpu::ORB_GPU orb(500, 1.2f, 1, 31, 0, 2, 0, 31);
	gpu::BruteForceMatcher_GPU<Hamming> matcher;
	vector<vector<DMatch> > matches;
	Mat erd = getStructuringElement(MORPH_RECT, Size(3,3));

	KalmanFilter KF(4, 2, 0);
	Mat_<float> state(4, 1); /* (x, y, Vx, Vy) */
	Mat processNoise(4, 1, CV_32F);
	Mat_<float> measurement(2,1); measurement.setTo(Scalar(0));
	Point pt(0, 0);


	PyrLKOpticalFlow pyrLK;

	pyrLK.winSize.width = 1920;
	pyrLK.winSize.height = 1080;
	pyrLK.maxLevel = 1;
	pyrLK.iters = 1;

	namedWindow( "Good Features to Track Detector", 0 );
	setMouseCallback( "Good Features to Track Detector", onMouse, 0 );

	bool paused = false;
	cap >> frame0;
	paused = true;
	vector<Point2f> prevPts, nextPts;
	vector<KeyPoint> kp, pkp, matched3;
	vector<uchar> status;
	vector<Point2f> ctr,kal;
	vector<KeyPoint> inliers1, inliers2;
	vector<Point2f> matched1, matched2;
	ctr.push_back(pt);
	kal.push_back(pt);

	for(;;)
	{
		if( !paused )
		{
			frame0.copyTo(frame1);
			cap >> frame0;
			if( frame0.empty() )
				break;
		}

		frame0.copyTo(image);

		if( !paused )
		{

			//gpu_gray.copyTo(gpu_frame1);

			gpu_frame0.upload(frame0);
			gpu::cvtColor(gpu_frame0, gpu_gray, COLOR_BGR2GRAY);

			if(trackObject < 0) {
				Point p = Point(selection.tl().x + (selection.width / 2), selection.tl().y + (selection.height / 2));
				//cout << "p" << p << endl;
				KF.statePre.at<float>(0) = p.x;
				KF.statePre.at<float>(1) = p.y;
				KF.statePre.at<float>(2) = 0;
				KF.statePre.at<float>(3) = 0;
				KF.transitionMatrix = *(Mat_<float>(4, 4) << 1,0,0,0,   0,1,0,0,  0,0,1,0,  0,0,0,1);

				setIdentity(KF.measurementMatrix);
				setIdentity(KF.processNoiseCov, Scalar::all(1e-4));
				setIdentity(KF.measurementNoiseCov, Scalar::all(1e-3));
				setIdentity(KF.errorCovPost, Scalar::all(.1));

				ctr.clear();
				kal.clear();

				trackObject = 1;
				gpu_mask = GpuMat(gpu_gray.size(), CV_8UC1, Scalar::all(0));
				gpu_mask(selection).setTo(Scalar::all(255));
				orb.operator()(gpu_gray, gpu_mask, next_points, next_desc);
				orb.downloadKeyPoints(next_points, kp);
				pkp = kp;
				next_points.copyTo(prev_points);
				next_desc.copyTo(prev_desc);
				continue;
			}
			if(trackObject){
//				pkp = kp;
//				next_points.copyTo(prev_points);
//				next_desc.copyTo(prev_desc);

				Mat prediction = KF.predict();
				Point predictPt(prediction.at<float>(0),prediction.at<float>(1));
//				cout << "selection" << selection.tl() + Point(selection.width/2, selection.height/2) << endl;
//				cout << "prediction" << predictPt << endl;
				if(predictPt.x != 0 || predictPt.y != 0){
					selection.x = predictPt.x - (selection.width/2);
					selection.y = predictPt.y - (selection.height/2);
				}
//				cout << "selection after prediction" <<  selection.tl() + Point(selection.width/2, selection.height/2) << endl;
				gpu_mask = GpuMat(gpu_gray.size(), CV_8UC1, Scalar::all(0));
				gpu_mask(selection).setTo(Scalar::all(255));

				//gpu::threshold(gpu_gray, gpu_gray, 200, 255, THRESH_BINARY);
				//gpu::Laplacian(gpu_gray, gpu_gray, gpu_gray.depth(), 3, 1.0, BORDER_DEFAULT);

				//gpu::erode(gpu_gray, gpu_gray, erd, Point(-1, -1), 1);
				gpu_gray.download(gray);

				//good(gpu_gray, next_points, gpu_mask);
//				fast(gpu_gray, gpu_mask, next_points);

				orb.operator()(gpu_gray, gpu_mask, next_points, next_desc);
				matcher.knnMatch(next_desc, prev_desc, matches, 2);//, gpu_mask, false);//mask can be added


				orb.downloadKeyPoints(next_points, kp);

				std::vector< DMatch > good_matches;
//				cerr << matches.size() << " Matches" << endl;
//				cerr << prev_desc.rows << " Desc Rows" << endl;
//				cerr << next_desc.rows << " Desc Rows" << endl;
//				cerr << kp.size() << " kp " << pkp.size() << endl;
				for(int k = 0; k < matches.size(); k++)
				{
					//cerr << matches[k].size();
					if((matches[k][0].distance < nn_match_ratio*(matches[k][1].distance)))// && (/*(int) matches[k].size()<=2 && */(int) matches[k].size()>0))
					{
						good_matches.push_back(matches[k][0]);
						//cerr << matches[k][0].trainIdx << matches[k][0].queryIdx << endl;
						matched1.push_back(pkp[matches[k][0].trainIdx].pt);
						matched2.push_back( kp[matches[k][0].queryIdx].pt);
						matched3.push_back( kp[matches[k][0].queryIdx]);
					}
				}
				if(good_matches.size() / kp.size() > 0.5){
					cerr << "good new image\n";
//					pkp = kp;
//					next_points.copyTo(prev_points);
//					next_desc.copyTo(prev_desc);

				} else {
					cerr << "bad match\n";
				}
				//cerr << "find matches " << good_matches.size() << endl;

				Mat inlier_mask, homography;

				vector<DMatch> inlier_matches;
				vector<Point2f> object_bb(4), new_bb(4);
				if(matched1.size() >= 4) {
					//cerr << matched1.size() << " " << matched2.size() << " " << ransac_thresh << endl;
					homography = findHomography(matched1, matched2, CV_RANSAC, ransac_thresh);//, inlier_mask);
					//cerr << "rect" << endl;
					Point2f tl = Point2f(selection.tl().x, selection.tl().y);
					object_bb[0] = tl;
					object_bb[1] = Point2f(tl.x + selection.width, tl.y);
					object_bb[2] = Point2f(tl.x, tl.y + selection.height);
					object_bb[3] = Point2f(tl.x + selection.width, tl.y + selection.height);

					perspectiveTransform(object_bb, new_bb, homography);

					//selection = Rect(new_bb[0], new_bb[3]);
				}

				//selection = newSelect;


				Point2f mean(0,0);
				//nextPts = vector<Point2f>(next_points.cols);
				//orb.downloadKeyPoints(next_points, kp);
				//cout << "download key" << endl;
				//for(int i = 0; i < kp.size(); i++){
				//	mean.x += kp[i].pt.x;
				//	mean.y += kp[i].pt.y;
				//}
				//mean.x = mean.x / kp.size();
				//mean.y = mean.y / kp.size();
				for(int i = 0; i < matched2.size(); i++){
					mean.x += matched2[i].x;
					mean.y += matched2[i].y;
				}
				mean.x = mean.x / matched2.size();
				mean.y = mean.y / matched2.size();
				//Point measp = Point(selection.tl().x + (selection.width / 2), selection.tl().y + (selection.height / 2));
				measurement(0) = mean.x;
				measurement(1) = mean.y;

				ctr.push_back(mean);

				Mat estimated = KF.correct(measurement);
				Point statePt(estimated.at<float>(0),estimated.at<float>(1));
				kal.push_back(statePt);
				selection.x = statePt.x - (selection.width/2);
				selection.y = statePt.y - (selection.height/2);
				//pyrLK.sparse(gpu_frame1, gpu_gray, prev_points, next_points, flow_status);

			}

			//prevPts = vector<Point2f>(prev_points.cols);
			//download(prev_points, prevPts);

			drawKeypoints(image, matched3, image, Scalar(255, 0, 0));
			drawKeypoints(gray, matched3, gray, Scalar(255, 0, 0));
			rectangle(image, selection, Scalar(0, 0, 255), 1, 8, 0);
			rectangle(gray, selection, Scalar(0, 0, 255), 1, 8, 0);
			circle( image, kal.back(), 4, Scalar(0, 0, 255), -1, 8, 0 );
			circle( gray, kal.back(), 4, Scalar(0, 0, 255), -1, 8, 0 );
			circle( image, ctr.back(), 4, Scalar(0, 255, 255), -1, 8, 0 );
			circle( gray, ctr.back(), 4, Scalar(0, 255, 255), -1, 8, 0 );
			imshow("lap",gray);
			matched1.clear();
			matched2.clear();
			matched3.clear();
//			nextPts = vector<Point2f>(next_points.cols);
//			download(next_points, nextPts);

			//status = vector<uchar>(flow_status.cols);
			//download(flow_status, status);
			//drawArrows(image, prevPts, nextPts, status, Scalar(0, 0, 255));
//			for( int i = 0; i < nextPts.size(); i++ )
//			{
//				circle( image, nextPts[i], 4, Scalar(255, 0, 0), -1, 8, 0 );
//				circle( gray, nextPts[i], 4, Scalar(255, 0, 0), -1, 8, 0 );
//			}
//			rectangle(image, selection, Scalar(0, 0, 255), 1, 8, 0);
//			rectangle(gray, selection, Scalar(255), 1, 8, 0);
//			imshow("lap",gray);
		}


		if( trackObject < 0 )
			paused = false;
		if( selectObject && selection.width > 0 && selection.height > 0 )
		{
			Mat mask(image, selection);
			bitwise_not(mask, mask);
		}
		imshow( "Good Features to Track Detector", image );

		char c = (char)waitKey(10);
		if( c == 27 )
			break;
		switch(c)
		{
		case 'c':
		trackObject = 0;
		break;
		case 'p':
		paused = !paused;
		break;
		default:
			;
		}
	}

	return 0;
}
